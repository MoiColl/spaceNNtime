{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac61e45-109e-4a65-97ae-089c24b73af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tskit\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "sys.path.append('../../scripts/')\n",
    "from spaceNNtime_templates import *\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a640314-1aec-4621-9378-2c6e62ab252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim, exp, nam, met, snp, pre, lay, dro, typ, cov, std, err, los, nfe, nla, wti, wsp, wsa, nod  = [\"europe\", \"9\", \"loss\", \"5\", \"1.0\", \"sNNt\", \"10\", \"0.25\", \"gt\", \"0\", \"0\", \"0.0\", \"mse\", \"None\", \"Norm1\", \"1\", \"10000\", \"None\", \"64\"]\n",
    "snp = float(snp)\n",
    "lay = int(lay)\n",
    "dro = float(dro)\n",
    "cov = float(cov)\n",
    "std = float(std)\n",
    "err = float(err)\n",
    "nod = int(nod)\n",
    "wti = float(wti)\n",
    "wsp = float(wsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820d9e7a-2646-472b-87ab-21285b036203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts            = tskit.load(\"../../data/{sim}/tree.trees\".format(sim = sim))\n",
    "metadata      = pd.read_csv(\"../../data/{sim}/metadata/{met}.txt\".format(sim = sim, met = met), delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a384f45-de6a-48e6-a9bf-b6e93f8eb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nam not in [\"loss\", \"reference\", \"downsample\", \"sampling\", \"snp_density\", \"prediction\", \"n_nodes\", \"dropout\", \"layers\"]:\n",
    "    cov_file_path = \"/home/moicoll/spaceNNtime/sandbox/{sim}/{exp}/coverage.txt\".format(sim = sim, exp = exp)\n",
    "    if os.path.isfile(cov_file_path):\n",
    "        cov = pd.read_table(cov_file_path)[[\"co1\", \"co2\"]].to_numpy().reshape(-1)\n",
    "    else:\n",
    "        ploidy = 2\n",
    "        cov = simGL.depth_per_haplotype(rng = np.random.default_rng(1234), mean_depth = cov/ploidy, std_depth = std/ploidy, n_hap = metadata.shape[0]*ploidy, ploidy = ploidy)\n",
    "        pd.DataFrame({\"ind\" : metadata[\"ind_id\"],\n",
    "                    \"co1\" : cov.reshape(-1, 2)[:, 0],\n",
    "                    \"co2\" : cov.reshape(-1, 2)[:, 1]}).to_csv(cov_file_path, mode='w', header=True, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f721797-3e7f-4a8b-8bf7-efd163910405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (1344, 1500)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "output shape: (1500, 3)\n",
      "[[5.36054544e+01 3.05757414e+01 3.86700000e+03]\n",
      " [3.73355222e+01 5.82851504e+01 4.07600000e+04]\n",
      " [3.78928083e+01 6.28855568e+01 3.53750000e+04]\n",
      " ...\n",
      " [5.11460970e+01 9.06849563e+00 9.90100000e+03]\n",
      " [5.47534622e+01 3.29253557e+01 8.86100000e+03]\n",
      " [3.80293684e+01 6.11433546e+01 3.97470000e+04]]\n",
      "Getting travaltes\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if wsa == \"None\":\n",
    "    wsa = np.ones(metadata.shape[0])\n",
    "elif wsa == \"coverage\":\n",
    "    wsa = cov.reshape(-1, 2).sum(axis = 1)\n",
    "\n",
    "input         = get_input(ts, metadata, snp, typ, cov, err)\n",
    "output        = get_output(pre, metadata)\n",
    "print(\"input shape:\", input.shape)\n",
    "print(input)\n",
    "print(\"output shape:\", output.shape)\n",
    "print(output)\n",
    "\n",
    "print(\"Getting travaltes\")\n",
    "tra_val_tes   = get_tra_val_tes(metadata[\"ind_id\"].to_numpy(), file = \"../../sandbox/{sim}/{met}/tra_val_tes_{met}.json\".format(sim = sim, met = met))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "335bad62-4504-424f-a157-85ac7c6c837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Feature-wise normalization of the data.\n",
       "\n",
       "This layer will coerce its inputs into a distribution centered around\n",
       "0 with standard deviation 1. It accomplishes this by precomputing the mean and\n",
       "variance of the data, and calling `(input - mean) / sqrt(var)` at runtime.\n",
       "\n",
       "What happens in `adapt()`: Compute mean and variance of the data and store\n",
       "them as the layer's weights. `adapt()` should be called before `fit()`,\n",
       "`evaluate()`, or `predict()`.\n",
       "\n",
       "Args:\n",
       "    axis: Integer, tuple of integers, or None. The axis or axes that should\n",
       "      have a separate mean and variance for each index in the shape. For\n",
       "      example, if shape is `(None, 5)` and `axis=1`, the layer will track 5\n",
       "      separate mean and variance values for the last axis. If `axis` is set to\n",
       "      `None`, the layer will normalize all elements in the input by a scalar\n",
       "      mean and variance. Defaults to -1, where the last axis of the input is\n",
       "      assumed to be a feature dimension and is normalized per index. Note that\n",
       "      in the specific case of batched scalar inputs where the only axis is the\n",
       "      batch axis, the default will normalize each index in the batch\n",
       "      separately. In this case, consider passing `axis=None`.\n",
       "    mean: The mean value(s) to use during normalization. The passed value(s)\n",
       "      will be broadcast to the shape of the kept axes above; if the value(s)\n",
       "      cannot be broadcast, an error will be raised when this layer's `build()`\n",
       "      method is called.\n",
       "    variance: The variance value(s) to use during normalization. The passed\n",
       "      value(s) will be broadcast to the shape of the kept axes above; if the\n",
       "      value(s) cannot be broadcast, an error will be raised when this layer's\n",
       "      `build()` method is called.\n",
       "\n",
       "Examples:\n",
       "\n",
       "Calculate a global mean and variance by analyzing the dataset in `adapt()`.\n",
       "\n",
       ">>> adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')\n",
       ">>> input_data = np.array([1., 2., 3.], dtype='float32')\n",
       ">>> layer = tf.keras.layers.Normalization(axis=None)\n",
       ">>> layer.adapt(adapt_data)\n",
       ">>> layer(input_data)\n",
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=\n",
       "array([-1.4142135, -0.70710677, 0.], dtype=float32)>\n",
       "\n",
       "Calculate a mean and variance for each index on the last axis.\n",
       "\n",
       ">>> adapt_data = np.array([[0., 7., 4.],\n",
       "...                        [2., 9., 6.],\n",
       "...                        [0., 7., 4.],\n",
       "...                        [2., 9., 6.]], dtype='float32')\n",
       ">>> input_data = np.array([[0., 7., 4.]], dtype='float32')\n",
       ">>> layer = tf.keras.layers.Normalization(axis=-1)\n",
       ">>> layer.adapt(adapt_data)\n",
       ">>> layer(input_data)\n",
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=\n",
       "array([0., 0., 0.], dtype=float32)>\n",
       "\n",
       "Pass the mean and variance directly.\n",
       "\n",
       ">>> input_data = np.array([[1.], [2.], [3.]], dtype='float32')\n",
       ">>> layer = tf.keras.layers.Normalization(mean=3., variance=2.)\n",
       ">>> layer(input_data)\n",
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-1.4142135 ],\n",
       "       [-0.70710677],\n",
       "       [ 0.        ]], dtype=float32)>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/sNNt_au/lib/python3.8/site-packages/keras/layers/preprocessing/normalization.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tf.keras.layers.Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37ac51a3-1142-4c5d-a5a1-1d1b93fa4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(nor, input_shape):\n",
    "    if nor == \"None\":\n",
    "        return tf.keras.layers.Normalization(input_shape=[input_shape, ], axis = None, mean = 0, variance = 1), 0, 1\n",
    "    elif nor == \"Norm0\":\n",
    "        \n",
    "        return tf.keras.layers.Normalization(input_shape=[input_shape, ], axis = None)\n",
    "    elif nor == \"Norm1\":\n",
    "        return tf.keras.layers.Normalization(input_shape=[input_shape, ], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fea1dfb-64c5-4b87-ba5c-56cb717611b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nla = \"Norm0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4bab2642-d04a-4566-9636-60c9c9cedd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "tf.random.set_seed(1234)\n",
    "i = str(i)\n",
    "print(\"Processing batch {}\".format(i), flush = True)\n",
    "norm_features   = normalizer(nor = nfe, input_shape = input.T.shape[1])\n",
    "if nfe != \"None\":\n",
    "    norm_features.adapt(input[:, tra_val_tes[i][\"tra\"]].T)\n",
    "norm_labels     = normalizer(nor = nla, input_shape = output.shape[1])\n",
    "if nla != \"None\":\n",
    "    norm_labels.adapt(output[tra_val_tes[i][\"tra\"], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d6fb2cb-7772-4e03-bd14-4d43804ba697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Norm0'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62e31001-aead-42ac-9a1a-0a0e00bfd16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.73355222e+01, 5.82851504e+01, 4.07600000e+04],\n",
       "       [3.78928083e+01, 6.28855568e+01, 3.53750000e+04],\n",
       "       [5.62063243e+01, 3.56497041e+01, 4.79900000e+03],\n",
       "       ...,\n",
       "       [5.11460970e+01, 9.06849563e+00, 9.90100000e+03],\n",
       "       [5.47534622e+01, 3.29253557e+01, 8.86100000e+03],\n",
       "       [3.80293684e+01, 6.11433546e+01, 3.97470000e+04]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output[tra_val_tes[i][\"tra\"], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46d8ce8b-5cc5-4042-8667-cd6e379ca6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6047972e-08"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_labels(output[tra_val_tes[i][\"tra\"], :]).numpy().mean(axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4ba7c87-dea2-43b3-82d9-d56563a85999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.9999995 , 0.99999964], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_labels(output[tra_val_tes[i][\"tra\"], :]).numpy().std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38fa0c18-41e4-4dbd-808f-69fe961da746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2b59c4aba460>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceNNtime(output_shape  = output.shape[1], \n",
    "                        norm          = norm_features, \n",
    "                        dropout_prop  = dro, \n",
    "                        l             = lay, \n",
    "                        n             = nod, \n",
    "                        loss_function = los, \n",
    "                        w_time        = wti, \n",
    "                        w_space       = wsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674600e7-b609-4079-8652-56b12689db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 1.6063088   0.17639016 -1.1250343 ]\n",
    " [ 0.7640381  -1.5982187  -0.93265826]\n",
    " [-1.2564942   0.46277282  1.337214  ]]\n",
    "(3, 3)\n",
    "m = [   42.62135567    40.77918183 25356.05048255]\n",
    "[8.76563130e+00 1.64173166e+01 1.44648645e+04]\n",
    "[[5.67016665e+01 4.36750349e+01 9.08258126e+03]\n",
    " [4.93186318e+01 1.45407197e+01 1.18652752e+04]\n",
    " [3.16073911e+01 4.83766697e+01 4.46986698e+04]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbdf1b00-3ac1-434e-9770-cbcc7fc8fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[ 1.6063088,0.17639016,-1.1250343 ],\n",
    " [ 0.7640381 , -1.5982187 , -0.93265826],\n",
    " [-1.2564942,0.46277282,1.337214  ]])\n",
    "m = np.array([[   42.62135567,40.77918183,25356.05048255]])\n",
    "s = np.array([[8.76563130e+00,1.64173166e+01,1.44648645e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5de133ae-2e0c-499d-b004-0647873063af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.67016664e+01, 4.36750349e+01, 9.08258178e+03],\n",
       "       [4.93186320e+01, 1.45407194e+01, 1.18652751e+04],\n",
       "       [3.16073908e+01, 4.83766697e+01, 4.46986698e+04]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a*s)+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d918174e-3bf3-432e-ad46-319ec8783543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff700a7d-252a-4025-bb84-026fde5550fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
